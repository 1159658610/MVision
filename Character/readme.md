# 文字识别 Optical Character Recognition,OCR

将图片上的文字内容，智能识别成为可编辑的文本。

> **应用:**

身份证、名片、银行卡、户口本等卡证类、出版物(扫描版图像、试题)、票据类(发票、火车票、彩票、出租车票)的印刷体识别；

运单、考试试卷、办公手写文档、快递手写单号等手写体识别；

车牌、集装箱号、快递运单、行驶证、驾驶证、等交通物流字符识别等；

水表、电表、燃气表等各种传感器可视化数据识别(5G物联网之后可能就不需要了);

## 什么是OCR？

OCR英文全称是Optical Character Recognition，中文叫做光学字符识别。它是利用光学技术和计算机技术把印在或写在纸上的文字读取出来，并转换成一种计算机能够接受、人又可以理解的格式。文字识别是计算机视觉研究领域的分支之一，而且这个课题已经是比较成熟了，并且在商业中已经有很多落地项目了。比如汉王OCR、百度OCR、阿里OCR、腾讯OCR等等，很多企业都有能力都是拿OCR技术开始挣钱了。其实我们自己也能感受到，OCR技术确实也在改变着我们的生活：比如一个手机APP就能帮忙扫描名片、身份证，并识别出里面的信息；汽车进入停车场、收费站都不需要人工登记了，都是用车牌识别技术；我们看书时看到不懂的题，拿个手机一扫，APP就能在网上帮你找到这题的答案。太多太多的应用了，OCR的应用在当今时代确实是百花齐放啊。


## OCR的分类

如果要给OCR进行分类，我觉得可以分为两类：**手写体识别和印刷体识别**。这两个可以认为是OCR领域两个大主题了，当然印刷体识别较手写体识别要简单得多，我们也能从直观上理解，印刷体大多都是规则的字体，因为这些字体都是计算机自己生成再通过打印技术印刷到纸上。在印刷体的识别上有其独特的干扰：在印刷过程中字体很可能变得断裂或者墨水粘连，使得OCR识别异常困难。当然这些都可以通过一些图像处理的技术帮他尽可能的还原，进而提高识别率。总的来说，单纯的印刷体识别在业界已经能做到很不错了，但说100%识别是肯定不可能的，但是说识别得不错那是没毛病。

印刷体已经识别得不错了，那么手写体呢？手写体识别一直是OCR界一直想攻克的难关，但是时至今天，感觉这个难关还没攻破，还有很多学者和公司在研究。为什么手写体识别这么难识别？因为人类手写的字往往带有个人特色，每个人写字的风格基本不一样，虽然人类可以读懂你写的文字，但是机器缺很难。那为什么机器能读懂印刷体？因为印刷体是机器造出来的啊，那机器当然能读懂自己造的字体啦哈哈~其实上面也提到了，印刷体一般都比较规则，字体都基本就那几十种，机器学习这几十种字体并不是一件难事，但是手写体，每个人都有一种字体的话，那机器该学习多少字体啊？这就是难度所在。

如果按识别的内容来分类，也就是按照识别的语言的分类的话，那么要识别的内容将是人类的所有语言**（汉语、英语、德语、法语等）**。如果仅按照我们国人的需求，那识别的内容就包括：**汉字、英文字母、阿拉伯数字、常用标点符号**。根据要识别的内容不同，识别的难度也各不相同。简单而言，识别数字是最简单了，毕竟要识别的字符只有0~9，而英文字母识别要识别的字符有26个（如果算上大小写的话那就52个），而中文识别，要识别的字符高达数千个（二级汉字一共6763个）！因为汉字的字形各不相同，结构非常复杂（比如带偏旁的汉字）如果要将这些字符都比较准确地识别出来，是一件相当具有挑战性的事情。但是，并不是所有应用都需要识别如此庞大的汉字集，比如车牌识别，我们的识别目标仅仅是数十个中国各省和直辖市的简称，难度就大大减少了。当然，在一些文档自动识别的应用是需要识别整个汉字集的，所以要保证识别的整体的识别还是很困难的。

传统OCR一般有 模板匹配的方法(简单的场景 单一数字识别)、特征设计提取分类(传统机器学习方法)

## 现代 OCR 流程
深度学习的出现，让OCR技术焕发第二春。现在OCR基本都用卷积神经网络来做了，而且识别率也是惊人的好，人们也不再需要花大量时间去设计字符特征了。在OCR系统中，人工神经网络主要充当特征提取器和分类器的功能，输入是字符图像，输出是识别结果，一气呵成。

* 1.图像预处理(做角度矫正和去噪)

[传统opencv 轮廓检测+透视变换+二值化](https://www.cnblogs.com/skyfsm/p/7324346.html)

最后总结一下两个算法的应用场景：

> 基于轮廓提取的矫正算法更适用于车牌、身份证、人民币、书本、发票一类矩形形状而且边界明显的物体矫正。

> 基于直线探测的矫正算法更适用于文本类的矫正。

[基于轮廓和直线的图片校正](https://www.cnblogs.com/skyfsm/p/6902524.html)

[cnn计算图像透视变换系数 Spatial Transformer Network(STN) ](https://arxiv.org/pdf/1506.02025.pdf)

对于弯曲不规则文本，如果按照之前的识别方法，直接将整个文本区域图像强行送入CNN+RNN，由于有大量的无效区域会导致识别效果很差。所以这篇文章提出一种通过**STN网络Spatial Transformer Network(STN)**学习变换参数，将Rectified Image对应的特征送入后续RNN中识别。

对于STN网络，可以学习一组点 (x_i^s,y_i^s) 到对应点 (x_i^t,y_i^t) 的变换。而且STN可以插入轻松任意网络结构中学习到对应的变换。

    (x_i^s,
    y_i^s)    =  (c11, c12, c13
                  c21, c22, c23)    *  (x_i^t,
                                        y_i^t,
                                        1) 
                                        
* 2.字符检测(行分割/列分 解决的问题是哪里有文字，文字的范围)

* 3.字符识别(单个字符识别/序列字符识别)

对定位好的文字区域进行识别，主要解决的问题是每个文字是什么，将图像中的文字区域进转化为字符信息.  

* 4.后处理识别矫正(语法检测器，检测字符的组合逻辑是否合理)






